I20241211 16:43:11 1057787 dinov2 config.py:59] git:
  sha: 0fb468b560ef5e9042659f548c04baa3938153eb, status: clean, branch: main

I20241211 16:43:11 1057787 dinov2 config.py:60] config_file: /fast/yangz16/outputs/cxr-million/vit_large_outputs/ibot333_highres512/config_interp.yaml
image_size: 512
n_last_blocks: 4
n_register_tokens: 4
num_classes: 40
opts: ['train.output_dir=/fast/yangz16/CheXFound']
output_dir: /fast/yangz16/CheXFound
patch_size: 16
pretrained_weights: None
return_class_token: True
target_class: Edema
I20241211 16:43:11 1057787 dinov2 config.py:26] sqrt scaling learning rate; base: 0.0002, new: 2.3385358667337133e-05
I20241211 16:43:11 1057787 dinov2 config.py:33] MODEL:
  WEIGHTS: /fast/yangz16/outputs/cxr-million/vit_large_outputs/ibot333_highres448/eval/training_249999/model_checkpoint.pth
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 131072
  head_bottleneck_dim: 384
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 3.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: true
  head_n_prototypes: 131072
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 14
  dataset_path: CXRDatabase:split=TRAIN:root=/fast/yangz16/outputs/dinov2_split_512:extra=/fast/yangz16/outputs/dinov2_split_512/extra
  output_dir: /fast/yangz16/CheXFound
  saveckp_freq: 20
  seed: 0
  num_workers: 40
  OFFICIAL_EPOCH_LENGTH: 2500
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.4
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: swiglufused
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 4
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.994
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.2
  base_lr: 0.0002
  lr: 2.3385358667337133e-05
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 1.0
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 512
  local_crops_size: 144
evaluation:
  eval_period_iterations: 5000

I20241211 16:43:11 1057787 dinov2 vision_transformer.py:125] using SwiGLU layer as FFN
W20241211 16:45:19 1057787 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241211 16:45:19 1057787 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

I20241211 16:45:32 1057787 fvcore.common.checkpoint checkpoint.py:150] [Checkpointer] Loading from /fast/yangz16/outputs/cxr-million/cxrlt/ibot333_512_eval_cxrlt_mldecoder_fl_labplus/model_final.pth ...
W20241211 16:45:35 1057787 fvcore.common.checkpoint checkpoint.py:352] The checkpoint state_dict contains keys that are not used by the model:
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.query_embed.weight[0m
W20241211 16:54:51 1057787 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241211 16:54:51 1057787 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

I20241211 16:54:58 1057787 fvcore.common.checkpoint checkpoint.py:150] [Checkpointer] Loading from /fast/yangz16/outputs/cxr-million/cxrlt/ibot333_512_eval_cxrlt_mldecoder_fl_labplus/model_final.pth ...
W20241211 16:54:59 1057787 fvcore.common.checkpoint checkpoint.py:352] The checkpoint state_dict contains keys that are not used by the model:
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.query_embed.weight[0m
W20241211 16:55:03 1057787 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241211 16:55:03 1057787 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

W20241211 16:58:23 1057787 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241211 16:58:23 1057787 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

W20241211 16:58:32 1057787 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241211 16:58:32 1057787 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

I20241211 16:59:44 1062717 dinov2 config.py:59] git:
  sha: 0fb468b560ef5e9042659f548c04baa3938153eb, status: clean, branch: main

I20241211 16:59:44 1062717 dinov2 config.py:60] config_file: /fast/yangz16/outputs/cxr-million/vit_large_outputs/ibot333_highres512/config_interp.yaml
image_size: 512
n_last_blocks: 4
n_register_tokens: 4
num_classes: 40
opts: ['train.output_dir=/fast/yangz16/CheXFound']
output_dir: /fast/yangz16/CheXFound
patch_size: 16
pretrained_weights: None
return_class_token: True
target_class: Cardiomegaly
I20241211 16:59:44 1062717 dinov2 config.py:26] sqrt scaling learning rate; base: 0.0002, new: 2.3385358667337133e-05
I20241211 16:59:44 1062717 dinov2 config.py:33] MODEL:
  WEIGHTS: /fast/yangz16/outputs/cxr-million/vit_large_outputs/ibot333_highres448/eval/training_249999/model_checkpoint.pth
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 131072
  head_bottleneck_dim: 384
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 3.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: true
  head_n_prototypes: 131072
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 14
  dataset_path: CXRDatabase:split=TRAIN:root=/fast/yangz16/outputs/dinov2_split_512:extra=/fast/yangz16/outputs/dinov2_split_512/extra
  output_dir: /fast/yangz16/CheXFound
  saveckp_freq: 20
  seed: 0
  num_workers: 40
  OFFICIAL_EPOCH_LENGTH: 2500
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.4
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: swiglufused
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 4
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.994
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.2
  base_lr: 0.0002
  lr: 2.3385358667337133e-05
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 1.0
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 512
  local_crops_size: 144
evaluation:
  eval_period_iterations: 5000

I20241211 16:59:44 1062717 dinov2 vision_transformer.py:125] using SwiGLU layer as FFN
W20241211 17:00:00 1062717 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241211 17:00:00 1062717 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

I20241211 17:00:10 1062717 fvcore.common.checkpoint checkpoint.py:150] [Checkpointer] Loading from /fast/yangz16/outputs/cxr-million/cxrlt/ibot333_512_eval_cxrlt_mldecoder_fl_labplus/model_final.pth ...
W20241211 17:00:11 1062717 fvcore.common.checkpoint checkpoint.py:352] The checkpoint state_dict contains keys that are not used by the model:
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.query_embed.weight[0m
W20241211 17:00:14 1062717 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241211 17:00:14 1062717 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

I20241212 10:41:05 1358356 dinov2 config.py:59] git:
  sha: 0fb468b560ef5e9042659f548c04baa3938153eb, status: clean, branch: main

I20241212 10:41:05 1358356 dinov2 config.py:60] config_file: /fast/yangz16/outputs/cxr-million/vit_large_outputs/ibot333_highres512/config_interp.yaml
image_size: 512
n_last_blocks: 4
n_register_tokens: 4
num_classes: 40
opts: ['train.output_dir=/fast/yangz16/CheXFound']
output_dir: /fast/yangz16/CheXFound
patch_size: 16
pretrained_weights: None
return_class_token: True
target_class: Cardiomegaly
I20241212 10:41:05 1358356 dinov2 config.py:26] sqrt scaling learning rate; base: 0.0002, new: 2.3385358667337133e-05
I20241212 10:41:05 1358356 dinov2 config.py:33] MODEL:
  WEIGHTS: /fast/yangz16/outputs/cxr-million/vit_large_outputs/ibot333_highres448/eval/training_249999/model_checkpoint.pth
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 131072
  head_bottleneck_dim: 384
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 3.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: true
  head_n_prototypes: 131072
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 14
  dataset_path: CXRDatabase:split=TRAIN:root=/fast/yangz16/outputs/dinov2_split_512:extra=/fast/yangz16/outputs/dinov2_split_512/extra
  output_dir: /fast/yangz16/CheXFound
  saveckp_freq: 20
  seed: 0
  num_workers: 40
  OFFICIAL_EPOCH_LENGTH: 2500
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.4
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: swiglufused
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 4
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.994
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.2
  base_lr: 0.0002
  lr: 2.3385358667337133e-05
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 1.0
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 512
  local_crops_size: 144
evaluation:
  eval_period_iterations: 5000

I20241212 10:41:05 1358356 dinov2 vision_transformer.py:125] using SwiGLU layer as FFN
W20241212 10:41:15 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241212 10:41:15 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

I20241212 10:41:15 1358356 fvcore.common.checkpoint checkpoint.py:150] [Checkpointer] Loading from /fast/yangz16/outputs/cxr-million/cxrlt/ibot333_512_eval_cxrlt_mldecoder_fl_labplus/model_final.pth ...
W20241212 10:41:16 1358356 fvcore.common.checkpoint checkpoint.py:352] The checkpoint state_dict contains keys that are not used by the model:
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.query_embed.weight[0m
W20241212 10:43:09 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241212 10:43:09 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

W20241212 10:43:51 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241212 10:43:51 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

W20241212 10:44:58 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241212 10:44:58 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

W20241212 10:45:36 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241212 10:45:36 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

W20241212 10:45:57 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241212 10:45:57 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

W20241212 10:48:52 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241212 10:48:52 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

W20241212 10:50:42 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241212 10:50:42 1358356 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

I20241212 10:57:07 1363486 chexfound config.py:59] git:
  sha: 0fb468b560ef5e9042659f548c04baa3938153eb, status: clean, branch: main

I20241212 10:57:07 1363486 chexfound config.py:60] config_file: /fast/yangz16/outputs/cxr-million/vit_large_outputs/ibot333_highres512/config_interp.yaml
image_size: 512
n_last_blocks: 4
n_register_tokens: 4
num_classes: 40
num_heads: 8
opts: ['train.output_dir=/fast/yangz16/CheXFound']
output_dir: /fast/yangz16/CheXFound
patch_size: 16
pretrained_weights: None
return_class_token: True
target_class: Cardiomegaly
I20241212 10:57:07 1363486 chexfound config.py:26] sqrt scaling learning rate; base: 0.0002, new: 2.3385358667337133e-05
I20241212 10:57:07 1363486 chexfound config.py:33] MODEL:
  WEIGHTS: /fast/yangz16/outputs/cxr-million/vit_large_outputs/ibot333_highres448/eval/training_249999/model_checkpoint.pth
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 131072
  head_bottleneck_dim: 384
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 3.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: true
  head_n_prototypes: 131072
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 14
  dataset_path: CXRDatabase:split=TRAIN:root=/fast/yangz16/outputs/dinov2_split_512:extra=/fast/yangz16/outputs/dinov2_split_512/extra
  output_dir: /fast/yangz16/CheXFound
  saveckp_freq: 20
  seed: 0
  num_workers: 40
  OFFICIAL_EPOCH_LENGTH: 2500
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.4
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: swiglufused
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 4
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.994
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.2
  base_lr: 0.0002
  lr: 2.3385358667337133e-05
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 1.0
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 512
  local_crops_size: 144
evaluation:
  eval_period_iterations: 5000

I20241212 10:57:07 1363486 chexfound vision_transformer.py:125] using SwiGLU layer as FFN
W20241212 10:57:18 1363486 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241212 10:57:18 1363486 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

I20241212 10:57:18 1363486 fvcore.common.checkpoint checkpoint.py:150] [Checkpointer] Loading from /fast/yangz16/outputs/cxr-million/cxrlt/ibot333_512_eval_cxrlt_mldecoder_fl_labplus/model_final.pth ...
W20241212 10:57:19 1363486 fvcore.common.checkpoint checkpoint.py:352] The checkpoint state_dict contains keys that are not used by the model:
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.query_embed.weight[0m
W20241212 10:57:25 1363486 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241212 10:57:25 1363486 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

W20241212 10:59:27 1363486 py.warnings warnings.py:109] /tmp/ipykernel_1363486/897700010.py:14: UserWarning: This figure was using a layout engine that is incompatible with subplots_adjust and/or tight_layout; not calling subplots_adjust.
  fig.subplots_adjust(wspace=0.01, hspace=0.01)

W20241212 10:59:38 1363486 py.warnings warnings.py:109] /tmp/ipykernel_1363486/658118038.py:14: UserWarning: This figure was using a layout engine that is incompatible with subplots_adjust and/or tight_layout; not calling subplots_adjust.
  fig.subplots_adjust(wspace=0.01, hspace=0.01)

I20241212 11:04:54 1365746 chexfound config.py:59] git:
  sha: 0fb468b560ef5e9042659f548c04baa3938153eb, status: clean, branch: main

I20241212 11:04:54 1365746 chexfound config.py:60] config_file: /fast/yangz16/outputs/cxr-million/vit_large_outputs/ibot333_highres512/config_interp.yaml
image_size: 512
n_last_blocks: 4
n_register_tokens: 4
num_classes: 40
num_heads: 8
opts: ['train.output_dir=/fast/yangz16/CheXFound']
output_dir: /fast/yangz16/CheXFound
patch_size: 16
pretrained_weights: None
return_class_token: True
target_class: Cardiomegaly
I20241212 11:04:55 1365746 chexfound config.py:26] sqrt scaling learning rate; base: 0.0002, new: 2.3385358667337133e-05
I20241212 11:04:55 1365746 chexfound config.py:33] MODEL:
  WEIGHTS: /fast/yangz16/outputs/cxr-million/vit_large_outputs/ibot333_highres448/eval/training_249999/model_checkpoint.pth
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 131072
  head_bottleneck_dim: 384
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 3.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: true
  head_n_prototypes: 131072
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 14
  dataset_path: CXRDatabase:split=TRAIN:root=/fast/yangz16/outputs/dinov2_split_512:extra=/fast/yangz16/outputs/dinov2_split_512/extra
  output_dir: /fast/yangz16/CheXFound
  saveckp_freq: 20
  seed: 0
  num_workers: 40
  OFFICIAL_EPOCH_LENGTH: 2500
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.4
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: swiglufused
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 4
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.994
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.2
  base_lr: 0.0002
  lr: 2.3385358667337133e-05
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 1.0
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 512
  local_crops_size: 144
evaluation:
  eval_period_iterations: 5000

I20241212 11:04:55 1365746 chexfound vision_transformer.py:125] using SwiGLU layer as FFN
I20241212 11:34:16 1374180 chexfound config.py:59] git:
  sha: 0fb468b560ef5e9042659f548c04baa3938153eb, status: clean, branch: main

I20241212 11:34:16 1374180 chexfound config.py:60] config_file: /fast/yangz16/outputs/cxr-million/vit_large_outputs/ibot333_highres512/config_interp.yaml
image_size: 512
n_last_blocks: 4
n_register_tokens: 4
num_classes: 40
num_heads: 8
opts: ['train.output_dir=/fast/yangz16/CheXFound']
output_dir: /fast/yangz16/CheXFound
patch_size: 16
pretrained_weights: None
return_class_token: True
target_class: Cardiomegaly
I20241212 11:34:16 1374180 chexfound config.py:26] sqrt scaling learning rate; base: 0.0002, new: 2.3385358667337133e-05
I20241212 11:34:16 1374180 chexfound config.py:33] MODEL:
  WEIGHTS: /fast/yangz16/outputs/cxr-million/vit_large_outputs/ibot333_highres448/eval/training_249999/model_checkpoint.pth
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 131072
  head_bottleneck_dim: 384
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 3.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: true
  head_n_prototypes: 131072
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 14
  dataset_path: CXRDatabase:split=TRAIN:root=/fast/yangz16/outputs/dinov2_split_512:extra=/fast/yangz16/outputs/dinov2_split_512/extra
  output_dir: /fast/yangz16/CheXFound
  saveckp_freq: 20
  seed: 0
  num_workers: 40
  OFFICIAL_EPOCH_LENGTH: 2500
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.4
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: swiglufused
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 4
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.994
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.2
  base_lr: 0.0002
  lr: 2.3385358667337133e-05
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 1.0
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 512
  local_crops_size: 144
evaluation:
  eval_period_iterations: 5000

I20241212 11:34:16 1374180 chexfound vision_transformer.py:125] using SwiGLU layer as FFN
W20241212 11:34:28 1374180 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241212 11:34:28 1374180 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

I20241212 11:34:28 1374180 fvcore.common.checkpoint checkpoint.py:150] [Checkpointer] Loading from /fast/yangz16/outputs/cxr-million/cxrlt/ibot333_512_eval_cxrlt_mldecoder_fl_labplus/model_final.pth ...
W20241212 11:34:29 1374180 fvcore.common.checkpoint checkpoint.py:352] The checkpoint state_dict contains keys that are not used by the model:
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.query_embed.weight[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.{duplicate_pooling, duplicate_pooling_bias}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.linear1.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.linear2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm2.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm3.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.embed_standart.{bias, weight}[0m
  [35mclassifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.query_embed.weight[0m
W20241212 11:34:40 1374180 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241212 11:34:40 1374180 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

W20241212 11:35:08 1374180 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241212 11:35:08 1374180 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

W20241212 11:37:11 1374180 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20241212 11:37:11 1374180 py.warnings warnings.py:109] /home/yangz16/anaconda3/envs/dinov2-extras/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

